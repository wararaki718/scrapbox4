{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import itertools\n",
    "\n",
    "from nltk.lm import Vocabulary\n",
    "from nltk.lm.models import KneserNeyInterpolated, Laplace, MLE, LanguageModel, WittenBellInterpolated\n",
    "from nltk.util import ngrams"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "N = 3\n",
    "train_filename = \"wiki-en-train.word\"\n",
    "test_filename = \"wiki-en-test.word\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def load_sentences(filename: str) -> list:\n",
    "    sentences = []\n",
    "    with open(filename, \"rt\") as f:\n",
    "        for line in f:\n",
    "            words = [\"__BOS__\"] + line.lower().strip().split() + [\"__EOS__\"]\n",
    "            sentences.append(words)\n",
    "    return sentences"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_sentences = load_sentences(train_filename)\n",
    "print(f\"the number of sentences in train dataset: {len(train_sentences)}\")\n",
    "test_sentences = load_sentences(test_filename)\n",
    "print(f\"the number of sentences in test dataset : {len(test_sentences)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the number of sentences in train dataset: 1301\n",
      "the number of sentences in test dataset : 171\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "vocabulary = Vocabulary(itertools.chain.from_iterable(train_sentences))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def get_dataset(sentences: list, n: int=3) -> list:\n",
    "    return [ngrams(sentence, n) for sentence in sentences]\n",
    "\n",
    "def get_model(sentences: list, n: int=3, model_type: str=\"mle\") -> LanguageModel:\n",
    "    dataset = get_dataset(sentences, n)\n",
    "\n",
    "    if model_type == \"mle\":\n",
    "        model = MLE(order=N, vocabulary=vocabulary)\n",
    "    elif model_type == \"laplace\":\n",
    "        model = Laplace(order=N, vocabulary=vocabulary)\n",
    "    elif model_type == \"kneser_ney\":\n",
    "        model = KneserNeyInterpolated(order=N, vocabulary=vocabulary)\n",
    "    elif model_type == \"witten_bell\":\n",
    "        model = WittenBellInterpolated(order=N, vocabulary=vocabulary)\n",
    "    else:\n",
    "        model = Laplace(order=N, vocabulary=vocabulary)\n",
    "    \n",
    "    model.fit(dataset)\n",
    "    return model\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "mle_model = get_model(train_sentences, N, \"mle\")\n",
    "lp_model = get_model(train_sentences, N, \"laplace\")\n",
    "kn_model = get_model(train_sentences, N, \"kneser_ney\")\n",
    "wb_model = get_model(train_sentences, N, \"witten_bell\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def evaluate(model: LanguageModel, sentences: list, n: int=3):\n",
    "    dataset = [[word for word in sentence] for sentence in get_dataset(sentences, n)]\n",
    "    pp = model.perplexity(dataset)\n",
    "    print(f\"{model.__class__.__name__} perplexity: {pp}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "evaluate(mle_model, test_sentences, N)\n",
    "evaluate(lp_model, test_sentences, N)\n",
    "evaluate(kn_model, test_sentences, N)\n",
    "evaluate(wb_model, test_sentences, N)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLE perplexity: inf\n",
      "Laplace perplexity: 4702.999999999891\n",
      "KneserNeyInterpolated perplexity: 4702.999999999891\n",
      "WittenBellInterpolated perplexity: inf\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('3.8.5': pyenv)"
  },
  "interpreter": {
   "hash": "72f9a84a8224ff9822e151d11f7230a84b9042f77e6225ea14b4f1e71494c010"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}