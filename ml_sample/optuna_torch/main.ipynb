{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(x: Union[nn.Module, torch.Tensor]) -> Union[nn.Module, torch.Tensor]:\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cuda()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(nn.Module):\n",
    "    def __init__(self, trial: optuna.trial.Trial, n_input: int=28*28, n_output: int=10):\n",
    "        super(NNModel, self).__init__()\n",
    "\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            n_hidden = trial.suggest_int(f\"n_units_l{i}\", 4, 128)\n",
    "            p = trial.suggest_float(f\"dropout_l{i}\", 0.2, 0.5)\n",
    "            layers.append(nn.Linear(n_input, n_hidden))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(p))\n",
    "            n_input = n_hidden\n",
    "        layers.append(nn.Linear(n_input, n_output))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(mnist_path: str, batch_size: int=128) -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(mnist_path, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(mnist_path, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, epochs: int=10, batch_size: int=128):\n",
    "    model = try_gpu(NNModel(trial))\n",
    "\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader, valid_loader = load_mnist(\"/mnt/d/dataset/mnist\", batch_size=batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_index, (data, target) in enumerate(train_loader):\n",
    "            if batch_index >= 30:\n",
    "                break\n",
    "\n",
    "            data = try_gpu(data.view(data.size(0), -1))\n",
    "            target = try_gpu(target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(data)\n",
    "            loss = F.nll_loss(y_pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_index, (data, target) in enumerate(valid_loader):\n",
    "                if batch_index >= 10:\n",
    "                    break\n",
    "\n",
    "                data = try_gpu(data.view(data.size(0), -1))\n",
    "                target = try_gpu(target)\n",
    "\n",
    "                y_pred = model(data)\n",
    "                y_label = y_pred.argmax(dim=1, keepdim=True)\n",
    "                correct += y_label.eq(target.view_as(y_label)).sum().item()\n",
    "        \n",
    "        accuracy = correct / min(len(valid_loader.dataset), batch_size * 10)\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-30 19:03:15,864]\u001b[0m A new study created in memory with name: no-name-7071fb18-3d70-4e2b-8551-2ec300099668\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /mnt/d/dataset/mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d985cc952f6042a0a38ec91dd1740f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/d/dataset/mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to /mnt/d/dataset/mnist/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /mnt/d/dataset/mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f112c000d041ce8c3638ba2e8ae524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/d/dataset/mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /mnt/d/dataset/mnist/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /mnt/d/dataset/mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e272c863f16343a8a0b99210fe294559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/d/dataset/mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /mnt/d/dataset/mnist/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /mnt/d/dataset/mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15891d188f594ca385124c89d19d8a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/d/dataset/mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /mnt/d/dataset/mnist/FashionMNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wararaki/.pyenv/versions/3.8.6/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-30 19:03:46,570]\u001b[0m Trial 0 finished with value: 0.09140625 and parameters: {'n_layers': 1, 'n_units_l0': 100, 'dropout_l0': 0.3398319065112406, 'optimizer': 'Adam', 'lr': 0.0006419330992797266}. Best is trial 0 with value: 0.09140625.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:03:52,786]\u001b[0m Trial 1 finished with value: 0.14296875 and parameters: {'n_layers': 2, 'n_units_l0': 44, 'dropout_l0': 0.3418626212899899, 'n_units_l1': 59, 'dropout_l1': 0.2838261521998486, 'optimizer': 'SGD', 'lr': 0.00018626623865679637}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:03:58,613]\u001b[0m Trial 2 finished with value: 0.1171875 and parameters: {'n_layers': 2, 'n_units_l0': 127, 'dropout_l0': 0.2791741961606878, 'n_units_l1': 28, 'dropout_l1': 0.3497017831376982, 'optimizer': 'SGD', 'lr': 0.008033568928213733}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:04,592]\u001b[0m Trial 3 finished with value: 0.09453125 and parameters: {'n_layers': 3, 'n_units_l0': 71, 'dropout_l0': 0.359941968106015, 'n_units_l1': 35, 'dropout_l1': 0.44607745193351256, 'n_units_l2': 80, 'dropout_l2': 0.4535352815354001, 'optimizer': 'SGD', 'lr': 0.00023376087294308632}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:10,226]\u001b[0m Trial 4 finished with value: 0.1015625 and parameters: {'n_layers': 2, 'n_units_l0': 113, 'dropout_l0': 0.2050710471784877, 'n_units_l1': 113, 'dropout_l1': 0.2184773763243324, 'optimizer': 'SGD', 'lr': 0.040624704330651365}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:11,368]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:12,129]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:12,885]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:13,673]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:20,043]\u001b[0m Trial 9 finished with value: 0.10703125 and parameters: {'n_layers': 3, 'n_units_l0': 98, 'dropout_l0': 0.23595213362705691, 'n_units_l1': 85, 'dropout_l1': 0.3351081697107689, 'n_units_l2': 51, 'dropout_l2': 0.31940803942039375, 'optimizer': 'Adam', 'lr': 2.6278132266106367e-05}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:20,761]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:21,520]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:22,280]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:23,032]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:28,646]\u001b[0m Trial 14 finished with value: 0.09921875 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_l0': 0.41530279743037457, 'optimizer': 'SGD', 'lr': 0.0031712000668470603}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:29,571]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:30,292]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:31,028]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:31,905]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:32,771]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:33,551]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:34,403]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:35,252]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:36,080]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:42,160]\u001b[0m Trial 24 finished with value: 0.1015625 and parameters: {'n_layers': 2, 'n_units_l0': 102, 'dropout_l0': 0.2571733478128785, 'n_units_l1': 75, 'dropout_l1': 0.3246209230053115, 'optimizer': 'Adam', 'lr': 0.00025735138497477917}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:48,267]\u001b[0m Trial 25 finished with value: 0.11171875 and parameters: {'n_layers': 2, 'n_units_l0': 97, 'dropout_l0': 0.286532724913515, 'n_units_l1': 88, 'dropout_l1': 0.38498107245125934, 'optimizer': 'Adam', 'lr': 0.00011662764576219123}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:49,005]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:49,748]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:56,142]\u001b[0m Trial 28 finished with value: 0.10078125 and parameters: {'n_layers': 2, 'n_units_l0': 118, 'dropout_l0': 0.3624743055050509, 'n_units_l1': 67, 'dropout_l1': 0.2580147323725907, 'optimizer': 'Adam', 'lr': 0.00013748483146444764}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:56,991]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:57,856]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:58,663]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:04:59,574]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:06,042]\u001b[0m Trial 33 finished with value: 0.09609375 and parameters: {'n_layers': 2, 'n_units_l0': 105, 'dropout_l0': 0.3497143484401186, 'n_units_l1': 105, 'dropout_l1': 0.32316130190930914, 'optimizer': 'Adam', 'lr': 4.506838788599175e-05}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:06,885]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:07,676]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:08,468]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:09,266]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:10,013]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:10,794]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:11,675]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:12,448]\u001b[0m Trial 41 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:13,253]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:14,004]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:14,765]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:15,571]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:16,290]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:17,043]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:17,839]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:23,997]\u001b[0m Trial 49 finished with value: 0.08828125 and parameters: {'n_layers': 2, 'n_units_l0': 86, 'dropout_l0': 0.2558074870740634, 'n_units_l1': 79, 'dropout_l1': 0.31301473468777324, 'optimizer': 'Adam', 'lr': 6.649839809788983e-05}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:30,063]\u001b[0m Trial 50 finished with value: 0.09921875 and parameters: {'n_layers': 2, 'n_units_l0': 101, 'dropout_l0': 0.27169092807745016, 'n_units_l1': 72, 'dropout_l1': 0.3531817910552605, 'optimizer': 'Adam', 'lr': 0.0001790880547963643}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:30,846]\u001b[0m Trial 51 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:31,675]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:32,511]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:33,292]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:34,181]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:34,918]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:35,775]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:36,518]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:37,299]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:38,089]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:38,839]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:39,650]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:45,787]\u001b[0m Trial 63 finished with value: 0.1 and parameters: {'n_layers': 2, 'n_units_l0': 108, 'dropout_l0': 0.33026940207797023, 'n_units_l1': 71, 'dropout_l1': 0.2290861538509451, 'optimizer': 'Adam', 'lr': 0.00024661969782347175}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:46,591]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:47,469]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:48,218]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:48,954]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:49,728]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:56,244]\u001b[0m Trial 69 finished with value: 0.09765625 and parameters: {'n_layers': 3, 'n_units_l0': 87, 'dropout_l0': 0.37438274949261763, 'n_units_l1': 110, 'dropout_l1': 0.29942218978158586, 'n_units_l2': 106, 'dropout_l2': 0.36570297298403964, 'optimizer': 'Adam', 'lr': 0.00022543386533584989}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:57,015]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:57,859]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:58,590]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:05:59,406]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:00,182]\u001b[0m Trial 74 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:00,950]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:01,756]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:07,762]\u001b[0m Trial 77 finished with value: 0.08984375 and parameters: {'n_layers': 2, 'n_units_l0': 126, 'dropout_l0': 0.31787809406494205, 'n_units_l1': 47, 'dropout_l1': 0.3850510220750426, 'optimizer': 'Adam', 'lr': 0.0015106606696350133}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:08,518]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:14,666]\u001b[0m Trial 79 finished with value: 0.09453125 and parameters: {'n_layers': 2, 'n_units_l0': 84, 'dropout_l0': 0.22603880913061514, 'n_units_l1': 94, 'dropout_l1': 0.4049701411880429, 'optimizer': 'Adam', 'lr': 0.00010891225231072741}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:15,477]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:21,717]\u001b[0m Trial 81 finished with value: 0.11015625 and parameters: {'n_layers': 2, 'n_units_l0': 99, 'dropout_l0': 0.2718833650901135, 'n_units_l1': 70, 'dropout_l1': 0.3552555826497924, 'optimizer': 'Adam', 'lr': 0.00017248245958772886}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:28,320]\u001b[0m Trial 82 finished with value: 0.0921875 and parameters: {'n_layers': 2, 'n_units_l0': 98, 'dropout_l0': 0.28376578975363825, 'n_units_l1': 71, 'dropout_l1': 0.3221087477090545, 'optimizer': 'Adam', 'lr': 0.00021057773130969006}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:29,100]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:29,924]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:30,693]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:31,551]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:32,399]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:33,145]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:33,983]\u001b[0m Trial 89 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:34,783]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:41,577]\u001b[0m Trial 91 finished with value: 0.09296875 and parameters: {'n_layers': 2, 'n_units_l0': 102, 'dropout_l0': 0.27329046240606053, 'n_units_l1': 72, 'dropout_l1': 0.3575570588842018, 'optimizer': 'Adam', 'lr': 0.00015992518209717458}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:48,892]\u001b[0m Trial 92 finished with value: 0.1 and parameters: {'n_layers': 1, 'n_units_l0': 35, 'dropout_l0': 0.4361807028366646, 'optimizer': 'SGD', 'lr': 0.0028545974406589984}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:56,214]\u001b[0m Trial 93 finished with value: 0.109375 and parameters: {'n_layers': 1, 'n_units_l0': 31, 'dropout_l0': 0.4844336433205282, 'optimizer': 'SGD', 'lr': 0.005070244196951356}. Best is trial 1 with value: 0.14296875.\u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:57,030]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:57,866]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:58,611]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:06:59,524]\u001b[0m Trial 97 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:07:00,393]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-30 19:07:01,409]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of finished trials: 100\n",
      "number of pruned trials  : 78\n",
      "number of complete trials: 22\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of finished trials: {len(study.trials)}\")\n",
    "print(f\"number of pruned trials  : {len(prune_trials)}\")\n",
    "print(f\"number of complete trials: {len(complete_trials)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best trial:\n",
      "  value: 0.14296875\n",
      "  param:\n",
      "     n_layers: 2\n",
      "     n_units_l0: 44\n",
      "     dropout_l0: 0.3418626212899899\n",
      "     n_units_l1: 59\n",
      "     dropout_l1: 0.2838261521998486\n",
      "     optimizer: SGD\n",
      "     lr: 0.00018626623865679637\n"
     ]
    }
   ],
   "source": [
    "print(\"best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  value: {trial.value}\")\n",
    "print(\"  param:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"     {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3cb06422c5e5e568dfcbabae8366a97e51436c74255e92eb95418ba0ce728d8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('3.8.6': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
